wandb: Currently logged in as: nashokkumar (ml4ed). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.3
wandb: Run data is saved locally in /work/nashokkumar_umass_edu/nipschal/Neurips-Challenge-22/wandb/run-20221012_035655-3gaz3t3p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run nips_embed_300_mask
wandb: â­ï¸ View project at https://wandb.ai/ml4ed/predict-graph
wandb: ğŸš€ View run at https://wandb.ai/ml4ed/predict-graph/runs/3gaz3t3p
/work/nashokkumar_umass_edu/nipschal/Neurips-Challenge-22/predict_graph_embed_mask.py:541: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(dataset_tensor[:, 1, :].clone().detach(), dtype=torch.long)
/work/nashokkumar_umass_edu/.conda/envs/nistorch/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: - 0.234 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: \ 5.617 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: | 16.500 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: / 28.125 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: - 40.054 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: \ 48.101 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: | 60.445 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: / 63.873 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: - 63.873 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: \ 63.873 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: | 63.873 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: / 63.873 MB of 63.873 MB uploaded (0.000 MB deduped)wandb: - 63.873 MB of 63.873 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:   Average training loss â–ˆâ–†â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb: Average validation loss â–†â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                   Epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:     Validation Accuracy â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         cur_least_epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:   Average training loss 0.01021
wandb: Average validation loss 0.01475
wandb:                   Epoch 99
wandb:     Validation Accuracy 0
wandb:         cur_least_epoch 21
wandb: 
wandb: Synced nips_embed_300_mask: https://wandb.ai/ml4ed/predict-graph/runs/3gaz3t3p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20221012_035655-3gaz3t3p/logs
