/var/spool/slurm/slurmd/job3367732/slurm_script: line 12: â€‹: command not found
/home/wanyongfeng_umass_edu/my-work/Neurips-Challenge-22/predict_graph.py:243: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.
  num_of_questions = stats.mode(simple_df["UserId"]).count[0]
Traceback (most recent call last):
  File "/home/wanyongfeng_umass_edu/my-work/Neurips-Challenge-22/predict_graph.py", line 326, in <module>
    main()
  File "/home/wanyongfeng_umass_edu/my-work/Neurips-Challenge-22/predict_graph.py", line 301, in main
    loss, acc = dkt(torch.stack(constructs).to(device), torch.stack(labels).to(device))
  File "/work/wanyongfeng_umass_edu/venvs/BOBCAT/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wanyongfeng_umass_edu/my-work/Neurips-Challenge-22/predict_graph.py", line 196, in forward
    hidden_states, _ = self.gru(input)
  File "/work/wanyongfeng_umass_edu/venvs/BOBCAT/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wanyongfeng_umass_edu/my-work/Neurips-Challenge-22/predict_graph.py", line 161, in forward
    hidden = self.cell(x, lower, hidden)
  File "/work/wanyongfeng_umass_edu/venvs/BOBCAT/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wanyongfeng_umass_edu/my-work/Neurips-Challenge-22/predict_graph.py", line 56, in forward
    W_hz = self.W_hz * lower.to(device)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 47.46 GiB total capacity; 46.57 GiB already allocated; 21.44 MiB free; 46.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
