PermutedDKT
Number of questions:  20
Number of students:  9
Number of concepts: 52
Using batch size: 64
Using batch size: 64
/work/nashokkumar_umass_edu/nipschal/Neurips-Challenge-22/predict_graph_embed_mask.py:546: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  labels = torch.tensor(dataset_tensor[:, 1, :].clone().detach(), dtype=torch.long)
AFTER LOADING THE MODEL
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |  280064 B  |  280064 B  |  280064 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |  280064 B  |  280064 B  |  280064 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |  280064 B  |  280064 B  |  280064 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |  280064 B  |  280064 B  |  280064 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1774 KB |    1987 KB |    1987 KB |  217600 B  |
|       from large pool |       0 KB |       0 KB |       0 KB |       0 B  |
|       from small pool |    1774 KB |    1987 KB |    1987 KB |  217600 B  |
|---------------------------------------------------------------------------|
| Allocations           |      14    |      14    |      14    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |      14    |      14    |      14    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |      14    |      14    |      14    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |      14    |      14    |      14    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       1    |       1    |       1    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       1    |       1    |       1    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
Successfull in data prepration!
Successfully loaded the optimizer
======== Epoch 1 / 100 ========
Training...
Step: 0
batch input size: batch input size:torch.Size([4, 20])  torch.Size([3, 20])Device:  Device:0 1
tensor([[-0.0136, -0.0190,  0.0003,  ...,  0.0433,  0.0381,  0.0397],
        [ 0.0010, -0.0135, -0.0453,  ..., -0.0081,  0.0124,  0.0410],
        [ 0.0331, -0.0087,  0.0067,  ...,  0.0036, -0.0303, -0.0194],
        ...,
        [ 0.0274, -0.0008,  0.0460,  ...,  0.0275,  0.0407, -0.0304],
        [-0.0285, -0.0410,  0.0217,  ..., -0.0182,  0.0050,  0.0400],
        [-0.0398,  0.0070, -0.0124,  ..., -0.0170,  0.0179, -0.0254]],
       device='cuda:1', grad_fn=<BroadcastBackward>)
tensor([[-0.0136, -0.0190,  0.0003,  ...,  0.0433,  0.0381,  0.0397],
        [ 0.0010, -0.0135, -0.0453,  ..., -0.0081,  0.0124,  0.0410],
        [ 0.0331, -0.0087,  0.0067,  ...,  0.0036, -0.0303, -0.0194],
        ...,
        [ 0.0274, -0.0008,  0.0460,  ...,  0.0275,  0.0407, -0.0304],
        [-0.0285, -0.0410,  0.0217,  ..., -0.0182,  0.0050,  0.0400],
        [-0.0398,  0.0070, -0.0124,  ..., -0.0170,  0.0179, -0.0254]],
       device='cuda:0', grad_fn=<BroadcastBackward>)
Traceback (most recent call last):
  File "/work/nashokkumar_umass_edu/nipschal/Neurips-Challenge-22/predict_graph_embed_mask.py", line 610, in <module>
    main()
  File "/work/nashokkumar_umass_edu/nipschal/Neurips-Challenge-22/predict_graph_embed_mask.py", line 595, in main
    model, epoch_train_loss, epoch_val_loss = train(epochs, dkt_model, train_dataloader, val_dataloader, optimizer, scheduler) # add val_dataloader later
  File "/work/nashokkumar_umass_edu/nipschal/Neurips-Challenge-22/predict_graph_embed_mask.py", line 434, in train
    loss = model(b_input_ids, b_labels, epoch_i+1)
  File "/work/nashokkumar_umass_edu/.conda/envs/nistorch/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/nashokkumar_umass_edu/.conda/envs/nistorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 169, in forward
    return self.gather(outputs, self.output_device)
  File "/work/nashokkumar_umass_edu/.conda/envs/nistorch/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 181, in gather
    return gather(outputs, output_device, dim=self.dim)
  File "/work/nashokkumar_umass_edu/.conda/envs/nistorch/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py", line 78, in gather
    res = gather_map(outputs)
  File "/work/nashokkumar_umass_edu/.conda/envs/nistorch/lib/python3.10/site-packages/torch/nn/parallel/scatter_gather.py", line 73, in gather_map
    return type(out)(map(gather_map, zip(*outputs)))
TypeError: 'float' object is not iterable