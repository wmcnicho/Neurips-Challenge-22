Using device: cuda
PermutedDKT
Number of questions:  1855
Number of students:  6468
Number of concepts: 1076
Using batch size: 64
Using batch size: 64
AFTER LOADING THE MODEL
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   39973 KB |   39973 KB |   39973 KB |       0 B  |
|       from large pool |   39967 KB |   39967 KB |   39967 KB |       0 B  |
|       from small pool |       6 KB |       6 KB |       6 KB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   39973 KB |   39973 KB |   39973 KB |       0 B  |
|       from large pool |   39967 KB |   39967 KB |   39967 KB |       0 B  |
|       from small pool |       6 KB |       6 KB |       6 KB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   63488 KB |   63488 KB |   63488 KB |       0 B  |
|       from large pool |   61440 KB |   61440 KB |   61440 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23514 KB |   23516 KB |   53176 KB |   29662 KB |
|       from large pool |   21473 KB |   21473 KB |   51133 KB |   29660 KB |
|       from small pool |    2041 KB |    2043 KB |    2043 KB |       2 KB |
|---------------------------------------------------------------------------|
| Allocations           |      14    |      14    |      14    |       0    |
|       from large pool |      11    |      11    |      11    |       0    |
|       from small pool |       3    |       3    |       3    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |      14    |      14    |      14    |       0    |
|       from large pool |      11    |      11    |      11    |       0    |
|       from small pool |       3    |       3    |       3    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Successfull in data prepration!
Successfully loaded the optimizer

======== Epoch 1 / 10 ========
Training...
Step: 0
batch input size:batch input size:  torch.Size([32, 1855])torch.Size([32, 1855])  Device:Device:  01

tensor([[ 0.0017, -0.0003,  0.0018,  ..., -0.0019, -0.0019,  0.0009],
        [ 0.0001, -0.0014, -0.0009,  ..., -0.0007,  0.0002,  0.0012],
        [ 0.0010, -0.0005,  0.0022,  ..., -0.0010, -0.0009, -0.0017],
        ...,
        [ 0.0022, -0.0012, -0.0018,  ..., -0.0013,  0.0007, -0.0019],
        [ 0.0021, -0.0010,  0.0016,  ..., -0.0002,  0.0019,  0.0018],
        [-0.0016, -0.0019, -0.0018,  ...,  0.0016, -0.0013, -0.0004]],
       device='cuda:1', grad_fn=<BroadcastBackward>)
tensor([[ 0.0017, -0.0003,  0.0018,  ..., -0.0019, -0.0019,  0.0009],
        [ 0.0001, -0.0014, -0.0009,  ..., -0.0007,  0.0002,  0.0012],
        [ 0.0010, -0.0005,  0.0022,  ..., -0.0010, -0.0009, -0.0017],
        ...,
        [ 0.0022, -0.0012, -0.0018,  ..., -0.0013,  0.0007, -0.0019],
        [ 0.0021, -0.0010,  0.0016,  ..., -0.0002,  0.0019,  0.0018],
        [-0.0016, -0.0019, -0.0018,  ...,  0.0016, -0.0013, -0.0004]],
       device='cuda:0', grad_fn=<BroadcastBackward>)
step loss: tensor([0.0314, 0.0023], device='cuda:0', grad_fn=<GatherBackward>)
AFTER FORWARD PASS
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2943 MB |    3325 MB |    6108 MB |    3165 MB |
|       from large pool |    1235 MB |    1615 MB |    1716 MB |     481 MB |
|       from small pool |    1708 MB |    1710 MB |    4391 MB |    2683 MB |
|---------------------------------------------------------------------------|
| Active memory         |    2943 MB |    3325 MB |    6108 MB |    3165 MB |
|       from large pool |    1235 MB |    1615 MB |    1716 MB |     481 MB |
|       from small pool |    1708 MB |    1710 MB |    4391 MB |    2683 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    3370 MB |    3370 MB |    3370 MB |       0 B  |
|       from large pool |    1634 MB |    1634 MB |    1634 MB |       0 B  |
|       from small pool |    1736 MB |    1736 MB |    1736 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   47907 KB |   47907 KB |    5175 MB |    5128 MB |
|       from large pool |   19341 KB |   31025 KB |     221 MB |     202 MB |
|       from small pool |   28565 KB |   28670 KB |    4953 MB |    4925 MB |
|---------------------------------------------------------------------------|
| Allocations           |   13042    |   13052    |   33539    |   20497    |
|       from large pool |      36    |      39    |      51    |      15    |
|       from small pool |   13006    |   13013    |   33488    |   20482    |
|---------------------------------------------------------------------------|
| Active allocs         |   13042    |   13052    |   33539    |   20497    |
|       from large pool |      36    |      39    |      51    |      15    |
|       from small pool |   13006    |   13013    |   33488    |   20482    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     884    |     884    |     884    |       0    |
|       from large pool |      16    |      16    |      16    |       0    |
|       from small pool |     868    |     868    |     868    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     880    |     881    |    8209    |    7329    |
|       from large pool |       8    |       8    |      13    |       5    |
|       from small pool |     872    |     873    |    8196    |    7324    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    2943 MB |    3325 MB |    6069 MB |    3126 MB |
|       from large pool |    1236 MB |    1616 MB |    1678 MB |     442 MB |
|       from small pool |    1706 MB |    1709 MB |    4390 MB |    2684 MB |
|---------------------------------------------------------------------------|
| Active memory         |    2943 MB |    3325 MB |    6069 MB |    3126 MB |
|       from large pool |    1236 MB |    1616 MB |    1678 MB |     442 MB |
|       from small pool |    1706 MB |    1709 MB |    4390 MB |    2684 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    3372 MB |    3372 MB |    3372 MB |       0 B  |
|       from large pool |    1636 MB |    1636 MB |    1636 MB |       0 B  |
|       from small pool |    1736 MB |    1736 MB |    1736 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   47766 KB |   49117 KB |    5099 MB |    5053 MB |
|       from large pool |   19852 KB |   27012 KB |     147 MB |     128 MB |
|       from small pool |   27914 KB |   29265 KB |    4952 MB |    4924 MB |
|---------------------------------------------------------------------------|
| Allocations           |   13030    |   13042    |   33503    |   20473    |
|       from large pool |      28    |      31    |      40    |      12    |
|       from small pool |   13002    |   13011    |   33463    |   20461    |
|---------------------------------------------------------------------------|
| Active allocs         |   13030    |   13042    |   33503    |   20473    |
|       from large pool |      28    |      31    |      40    |      12    |
|       from small pool |   13002    |   13011    |   33463    |   20461    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     885    |     885    |     885    |       0    |
|       from large pool |      17    |      17    |      17    |       0    |
|       from small pool |     868    |     868    |     868    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     877    |     879    |    8194    |    7317    |
|       from large pool |       7    |       7    |      11    |       4    |
|       from small pool |     870    |     872    |    8183    |    7313    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Step: 1
batch input size:batch input size: torch.Size([32, 1855]) Device: 0
 torch.Size([32, 1855]) Device: 1
