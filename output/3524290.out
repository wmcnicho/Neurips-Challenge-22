Using device: cuda
PermutedDKT
Number of questions:  1855
Number of students:  6468
Number of concepts: 1076
Using batch size: 64
Using batch size: 64
AFTER LOADING THE MODEL
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   39973 KB |   39973 KB |   39973 KB |       0 B  |
|       from large pool |   39967 KB |   39967 KB |   39967 KB |       0 B  |
|       from small pool |       6 KB |       6 KB |       6 KB |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |   39973 KB |   39973 KB |   39973 KB |       0 B  |
|       from large pool |   39967 KB |   39967 KB |   39967 KB |       0 B  |
|       from small pool |       6 KB |       6 KB |       6 KB |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   63488 KB |   63488 KB |   63488 KB |       0 B  |
|       from large pool |   61440 KB |   61440 KB |   61440 KB |       0 B  |
|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23514 KB |   23516 KB |   53176 KB |   29662 KB |
|       from large pool |   21473 KB |   21473 KB |   51133 KB |   29660 KB |
|       from small pool |    2041 KB |    2043 KB |    2043 KB |       2 KB |
|---------------------------------------------------------------------------|
| Allocations           |      14    |      14    |      14    |       0    |
|       from large pool |      11    |      11    |      11    |       0    |
|       from small pool |       3    |       3    |       3    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |      14    |      14    |      14    |       0    |
|       from large pool |      11    |      11    |      11    |       0    |
|       from small pool |       3    |       3    |       3    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       4    |       4    |       4    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

Successfull in data prepration!
Successfully loaded the optimizer

======== Epoch 1 / 10 ========
Training...
Step: 0
batch input size:batch input size:  torch.Size([32, 1855])torch.Size([32, 1855])  Device:Device: 0 
1
tensor([[ 0.0017, -0.0003,  0.0018,  ..., -0.0019, -0.0019,  0.0009],
        [ 0.0001, -0.0014, -0.0009,  ..., -0.0007,  0.0002,  0.0012],
        [ 0.0010, -0.0005,  0.0022,  ..., -0.0010, -0.0009, -0.0017],
        ...,
        [ 0.0022, -0.0012, -0.0018,  ..., -0.0013,  0.0007, -0.0019],
        [ 0.0021, -0.0010,  0.0016,  ..., -0.0002,  0.0019,  0.0018],
        [-0.0016, -0.0019, -0.0018,  ...,  0.0016, -0.0013, -0.0004]],
       device='cuda:1', grad_fn=<BroadcastBackward>)
tensor([[ 0.0017, -0.0003,  0.0018,  ..., -0.0019, -0.0019,  0.0009],
        [ 0.0001, -0.0014, -0.0009,  ..., -0.0007,  0.0002,  0.0012],
        [ 0.0010, -0.0005,  0.0022,  ..., -0.0010, -0.0009, -0.0017],
        ...,
        [ 0.0022, -0.0012, -0.0018,  ..., -0.0013,  0.0007, -0.0019],
        [ 0.0021, -0.0010,  0.0016,  ..., -0.0002,  0.0019,  0.0018],
        [-0.0016, -0.0019, -0.0018,  ...,  0.0016, -0.0013, -0.0004]],
       device='cuda:0', grad_fn=<BroadcastBackward>)
